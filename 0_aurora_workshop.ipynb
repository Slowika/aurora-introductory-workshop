{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Aurora fine‑tuning workshop - master notebook\n",
        "\n",
        "This is the **one notebook you run**.\n",
        "\n",
        "It drives everything by submitting **one Azure ML job** to your GPU cluster.  \n",
        "That job runs `run_aurora_job.py`, which then calls functions in `aurora_demo_core.py`.\n",
        "\n",
        "You can use this notebook to run:\n",
        "\n",
        "- **Toy mode** (quick sanity check - random inputs, dummy loss)\n",
        "- **ERA5 short‑lead fine‑tuning**\n",
        "- **ERA5 rollout / autoregressive inference**\n",
        "- **ERA5 rollout fine‑tuning** (long‑lead) with **LoRA**\n",
        "- **Add one extra variable**\n"
      ],
      "metadata": {},
      "id": "7ef191c5-de35-4d69-9cae-a6bff5aa391f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Files used in this workshop\n",
        "\n",
        "You will mainly touch **three files**:\n",
        "\n",
        "1) **`0_aurora_workshop.ipynb`** (this notebook)  \n",
        "   The “remote control”. You pick a run profile and submit a job.\n",
        "\n",
        "2) **`run_aurora_job.py`**  \n",
        "   The Azure ML entrypoint that reads environment variables and decides what to run.\n",
        "\n",
        "3) **`aurora_demo_core.py`**  \n",
        "   The core logic: batch creation, inference, short‑lead fine‑tuning, rollout fine‑tuning, LoRA, extra variable support."
      ],
      "metadata": {},
      "id": "225910af-3650-4ea9-9c16-5db191c12a0e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Before you run\n",
        "\n",
        "### 1) You need a GPU compute cluster\n",
        "Set `COMPUTE_NAME` to the name of your Azure ML compute cluster.  \n",
        "This should be created with **Standard_NC40ads_H100_v5**.\n",
        "\n",
        "### 2) You need an environment that has Aurora installed\n",
        "Set `ENV_NAME` to the Azure ML custom environment.\n",
        "\n",
        "### 3) If you want ERA5 runs, you need two data assets\n",
        "- **Dynamic ERA5 subset**: Zarr folder (URI_FOLDER)  \n",
        "- **Static file**: `era5_static.nc` (URI_FILE) containing `lsm`, `slt`, `z`\n",
        "\n"
      ],
      "metadata": {},
      "id": "1bf500db-63ce-4f03-99cd-a6864e2cf61d"
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) If your notebook kernel is missing packages, uncomment these.\n",
        "%pip -q install azure-ai-ml azure-identity numpy matplotlib xarray zarr gcsfs netcdf4\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\r\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/anaconda/envs/azureml_py310_sdkv2/bin/python -m pip install --upgrade pip\u001b[0m\r\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1768465497303
        }
      },
      "id": "16661f52-ecb9-48dd-8b51-b937a5c81cd3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the PARTICIPANT_ID below to make sure your Jobs/experimets are trackable and you have a separate output path\n",
        "PARTICIPANT_ID = \"saadat\"   # TODO: each participant changes this"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1768465500229
        }
      },
      "id": "f8a59c59-9456-486f-a142-c09c8125c030"
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the Azure ML workspace\n",
        "\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "try:\n",
        "    ml_client = MLClient.from_config(DefaultAzureCredential())\n",
        "    print(\"Connected using MLClient.from_config()\")\n",
        "except Exception as e:\n",
        "    print(\"MLClient.from_config() failed. Falling back to manual settings.\")\n",
        "    print(\"Error:\", repr(e))\n",
        "\n",
        "    # ---- Fallback: fill these in  ----\n",
        "    SUBSCRIPTION_ID = \"62118f5c-be37-400f-9f20-a8b77a2a7877\"\n",
        "    RESOURCE_GROUP  = \"aurora-workshop-rg\"\n",
        "    WORKSPACE_NAME  = \"aurora-workshop-aml-ws\"\n",
        "\n",
        "    ml_client = MLClient(\n",
        "        credential=DefaultAzureCredential(),\n",
        "        subscription_id=SUBSCRIPTION_ID,\n",
        "        resource_group_name=RESOURCE_GROUP,\n",
        "        workspace_name=WORKSPACE_NAME,\n",
        "    )\n",
        "\n",
        "print(\"Workspace:\", ml_client.workspace_name)\n",
        "\n",
        "# ---- Set your compute + environment here ----\n",
        "COMPUTE_NAME = \"aurora-ws-gpu-ins\"        # TODO: Azure ML compute cluster name\n",
        "ENV_NAME     = \"azureml:aurora-environment:3\" # TODO: Azure ML environment name\n",
        "\n",
        "print(\"Compute:\", COMPUTE_NAME)\n",
        "print(\"Environment:\", ENV_NAME)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Found the config file in: /config.json\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Connected using MLClient.from_config()\nWorkspace: aurora-workshop-aml-ws\nCompute: aurora-ws-gpu-ins\nEnvironment: azureml:aurora-environment:3\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1768465508315
        }
      },
      "id": "a34aaeef-b25a-4bc9-b038-4d3879ebf00c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional) Register your ERA5 subset as Data Assets\n",
        "\n",
        "### Skip This as Data Assets are already registered\n",
        "### \n",
        "**If you already registered the data assets, skip this section.\n",
        "\n",
        "You will register:\n",
        "- the **dynamic Zarr folder** as a **URI_FOLDER**\n",
        "- the **static NetCDF** as a **URI_FILE**\n"
      ],
      "metadata": {},
      "id": "7b6fbdfb-b1fa-4228-aeb1-7234790f9833"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register Data Assets (Optional, If not registered before)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "200fdb8a-fcff-4bc6-964d-a4a27b0da155"
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: register local files as Azure ML Data Assets\n",
        "\n",
        "# Only required to do this once. After that, you can just use the azureml:... references\n",
        "# in the next cells.\n",
        "\n",
        "DO_REGISTER_ASSETS = False # As We have already registered the data assets hence we are setting this as False\n",
        "\n",
        "# If True, set these to your local paths \n",
        "LOCAL_ERA5_ZARR_PATH   = r\"../era5_subsets/era5_aurora_2025-09_6hourly.zarr\" # Folder (Zarr store)\n",
        "LOCAL_ERA5_STATIC_PATH = r\"../era5_subsets/era5_static.nc\"                 # file (NetCDF file)\n",
        "\n",
        "if DO_REGISTER_ASSETS:\n",
        "    from azure.ai.ml.entities import Data\n",
        "    from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "    # Pick names\n",
        "    DYNAMIC_NAME = \"era5_aurora_2025-09_6hourly_zarr\"\n",
        "    STATIC_NAME  = \"era5_static_nc\"\n",
        "\n",
        "    dynamic_asset = Data(\n",
        "        name=DYNAMIC_NAME,\n",
        "        version=\"2\",\n",
        "        type=AssetTypes.URI_FOLDER,\n",
        "        path=LOCAL_ERA5_ZARR_PATH,\n",
        "        description=\"ERA5 subset for Aurora workshop (dynamic variables, 6-hourly).\",\n",
        "    )\n",
        "\n",
        "    static_asset = Data(\n",
        "        name=STATIC_NAME,\n",
        "        version=\"2\",\n",
        "        type=AssetTypes.URI_FILE,\n",
        "        path=LOCAL_ERA5_STATIC_PATH,\n",
        "        description=\"Static fields for Aurora workshop (lsm, slt, z).\",\n",
        "    )\n",
        "\n",
        "    dynamic_asset = ml_client.data.create_or_update(dynamic_asset)\n",
        "    static_asset  = ml_client.data.create_or_update(static_asset)\n",
        "\n",
        "    print(\"Registered dynamic asset:\", f\"azureml:{dynamic_asset.name}:{dynamic_asset.version}\")\n",
        "    print(\"Registered static asset :\", f\"azureml:{static_asset.name}:{static_asset.version}\")\n",
        "else:\n",
        "    print(\"Skipping asset registration (DO_REGISTER_ASSETS=False).\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Your file exceeds 100 MB. If you experience low speeds, latency, or broken connections, we recommend using the AzCopyv10 tool for this file transfer.\n\nExample: azcopy copy '/mnt/batch/tasks/shared/LS_root/mounts/clusters/aurora-ws-cpu-cls/code/Users/saadatali/era5_subsets/era5_aurora_2025-09_6hourly.zarr' 'https://auroraworkshop7918090421.blob.core.windows.net/azureml-blobstore-fe6df4e0-19e0-41f0-9fdb-8eddf05a138a/LocalUpload/379a26ba761d6e084916a45b15f7223e7e3700590307d816a23fc98e17095560/era5_aurora_2025-09_6hourly.zarr' \n\nSee https://learn.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n\u001b[32mUploading era5_static.nc\u001b[32m (< 1 MB): 100%|██████████| 12.5M/12.5M [00:00<00:00, 54.6MB/s]"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Registered dynamic asset: azureml:era5_aurora_2025-09_6hourly_zarr:2\nRegistered static asset : azureml:era5_static_nc:2\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1768216524105
        }
      },
      "id": "ce721cd5-0b7b-4aeb-835f-c5c33f8ba65c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pick a run profile\n",
        "\n",
        "Pick a **profile** below, and the notebook will set sensible defaults.\n",
        "\n",
        "### Profiles you can use\n",
        "- `toy`  \n",
        "  Quick sanity check. No ERA5 inputs needed. We are creating dummy data\n",
        "\n",
        "- `era5_short`  \n",
        "  Real short‑lead fine‑tuning on ERA5: `[t-6h, t] → t+6h`.\n",
        "\n",
        "- `era5_short_lora`  \n",
        "  Same as above, but trains LoRA only.\n",
        "\n",
        "- `era5_rollout_infer_48h`  \n",
        "  Autoregressive **inference** for 8 steps (48 hours at 6h lead).\n",
        "\n",
        "- `era5_rollout_ft_safe`  \n",
        "  Rollout **fine‑tuning** with LoRA, light settings.\n",
        "\n",
        "- `era5_rollout_ft_2days`  \n",
        "  Rollout fine‑tuning with LoRA for 8 steps (48h).\n",
        "\n",
        "- `era5_add_variable_demo`  \n",
        "  Shows how to add **one extra surface variable**.  \n",
        "  You must point `ERA5_ZARR_ASSET` to a PLUS dataset that actually contains that variable.\n",
        "\n",
        "### A note on “stages”\n",
        "- In inference, stages = `INFER_ROLLOUT_STEPS`\n",
        "- In rollout fine‑tuning, stages per update = `ROLLOUT_HORIZON_STEPS`\n",
        "\n",
        "Runtime roughly scales like:\n",
        "`FINETUNE_STEPS × ROLLOUT_HORIZON_STEPS`\n"
      ],
      "metadata": {},
      "id": "5d63edda-7416-4326-a92a-2c87b6e46a5b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose your profile and configure assets\n",
        "# ----------------------------------------\n",
        "# Fill in your Data Asset references here.\n",
        "#\n",
        "# If you want to run the \"add variable\" demo, create a PLUS dataset (separate Zarr folder)\n",
        "# that includes the extra variable, register it as a Data Asset, and point ERA5_ZARR_ASSET\n",
        "# to that PLUS dataset.\n",
        "\n",
        "# Base dataset (no extra variables)\n",
        "ERA5_ZARR_ASSET   = \"azureml:era5_aurora_2025-09_6hourly_zarr:2\"   # TODO: replace\n",
        "ERA5_STATIC_ASSET = \"azureml:era5_static_nc:2\"                  # TODO: replace\n",
        "\n",
        "# Additional dataset with extra variable\n",
        "ERA5_ZARR_ASSET_PLUS = \"azureml:era5_aurora_2025-09_6hourly_PLUS_2m_dewpoint_temperature:1\"  # TODO: replace\n",
        "\n",
        "# Safe crop sizes (global 721x1440 is too big for workshop training)\n",
        "CROP_LAT = 128\n",
        "CROP_LON = 256   # keep lon multiple of 4\n",
        "\n",
        "# Learning rate used for fine-tuning\n",
        "# The learning rate (LR) controls how big each weight update is each step.\n",
        "# Too big → updates jump too far, training can become unstable (loss spikes, model “breaks”).\n",
        "# Too small → training is very slow (loss barely moves).\n",
        "# 3e-5 means 3 × 10⁻⁵ which equals to 0.00003\n",
        "\n",
        "LR = 3e-5\n",
        "\n",
        "# Profiles: env vars we pass to the Azure ML job\n",
        "\n",
        "\n",
        "profiles = {\n",
        "\n",
        "     # It creates a fake Aurora Batch (random data).\n",
        "     # Runs inference.\n",
        "     # Does 3 training updates\n",
        "\n",
        "    \"toy\": {                      \n",
        "        \"FLOW\": \"toy\",           \n",
        "        \"FINETUNE_STEPS\": \"3\",\n",
        "        \"DEVICE\": \"cuda\",\n",
        "    },\n",
        "\n",
        "    # --- ERA5 short-lead ---\n",
        "    # Short Lead Training using ERA5 data\n",
        "\n",
        "\n",
        "    \"era5_short\": {\n",
        "        \"FLOW\": \"era5\",\n",
        "        \"FT_MODE\": \"short\",\n",
        "        \"FINETUNE_STEPS\": \"5\",\n",
        "        \"ERA5_LEAD_HOURS\": \"6\",\n",
        "        \"ERA5_CROP_LAT\": str(CROP_LAT),\n",
        "        \"ERA5_CROP_LON\": str(CROP_LON),\n",
        "        \"ERA5_TIME_INDEX\": \"10\",\n",
        "        \"AUTOCAST\": \"1\",\n",
        "        \"LR\": str(LR),\n",
        "        \"USE_LORA\": \"0\",\n",
        "        \"LOG_MLFLOW\": \"1\",\n",
        "        \"RUN_NAME\": \"era5_short_lora\",\n",
        "\n",
        "\n",
        "    },\n",
        "\n",
        "    \"era5_short_lora\": {\n",
        "        \"FLOW\": \"era5\",\n",
        "        \"FT_MODE\": \"short\",\n",
        "        \"FINETUNE_STEPS\": \"5\",\n",
        "        \"ERA5_LEAD_HOURS\": \"6\",\n",
        "        \"ERA5_CROP_LAT\": str(CROP_LAT),\n",
        "        \"ERA5_CROP_LON\": str(CROP_LON),\n",
        "        \"ERA5_TIME_INDEX\": \"10\",\n",
        "        \"AUTOCAST\": \"1\",\n",
        "        \"LR\": str(LR),\n",
        "        \"USE_LORA\": \"1\",\n",
        "        \"TRAIN_LORA_ONLY\": \"1\",\n",
        "        \"LORA_MODE\": \"single\",\n",
        "        \"LORA_STEPS\": \"40\",\n",
        "        \"LOG_MLFLOW\": \"1\",\n",
        "    },\n",
        "\n",
        "    # --- Autoregressive inference (no training) ---\n",
        "    \"era5_rollout_infer_48h\": {\n",
        "        \"FLOW\": \"era5\",\n",
        "        \"FT_MODE\": \"short\",              # fine-tune mode doesn't matter when FINETUNE_STEPS=0\n",
        "        \"FINETUNE_STEPS\": \"0\",\n",
        "        \"ERA5_LEAD_HOURS\": \"6\",\n",
        "        \"ERA5_CROP_LAT\": str(CROP_LAT),\n",
        "        \"ERA5_CROP_LON\": str(CROP_LON),\n",
        "        \"ERA5_TIME_INDEX\": \"10\",\n",
        "        \"AUTOCAST\": \"1\",\n",
        "        \"INFER_ROLLOUT_STEPS\": \"8\",      # 8 × 6h = 48 hours\n",
        "    },\n",
        "\n",
        "    # --- Rollout fine-tuning (safe starter) ---\n",
        "    \"era5_rollout_ft_safe\": {\n",
        "        \"FLOW\": \"era5\",\n",
        "        \"FT_MODE\": \"rollout\",\n",
        "        \"FINETUNE_STEPS\": \"2\",\n",
        "        \"ROLLOUT_HORIZON_STEPS\": \"4\",    # 4 × 6h = 24h horizon per update (fast + safe)\n",
        "        \"ROLLOUT_LOSS_ON\": \"last\",       # last = cheaper on memory (recommended)\n",
        "        \"ERA5_LEAD_HOURS\": \"6\",\n",
        "        \"ERA5_CROP_LAT\": str(CROP_LAT),\n",
        "        \"ERA5_CROP_LON\": str(CROP_LON),\n",
        "        \"ERA5_TIME_INDEX\": \"10\",\n",
        "        \"AUTOCAST\": \"1\",\n",
        "        \"LR\": str(LR),\n",
        "        \"USE_LORA\": \"1\",\n",
        "        \"TRAIN_LORA_ONLY\": \"1\",\n",
        "        \"LORA_MODE\": \"all\",\n",
        "        \"LORA_STEPS\": \"40\",\n",
        "        \"LOG_MLFLOW\": \"1\",\n",
        "    },\n",
        "\n",
        "    \"era5_rollout_ft_2days\": {\n",
        "        \"FLOW\": \"era5\",\n",
        "        \"FT_MODE\": \"rollout\",\n",
        "        \"FINETUNE_STEPS\": \"3\",\n",
        "        \"ROLLOUT_HORIZON_STEPS\": \"8\",    # 8 × 6h = 48h horizon per update\n",
        "        \"ROLLOUT_LOSS_ON\": \"last\",\n",
        "        \"ERA5_LEAD_HOURS\": \"6\",\n",
        "        \"ERA5_CROP_LAT\": str(CROP_LAT),\n",
        "        \"ERA5_CROP_LON\": str(CROP_LON),\n",
        "        \"ERA5_TIME_INDEX\": \"10\",\n",
        "        \"AUTOCAST\": \"1\",\n",
        "        \"LR\": str(LR),\n",
        "        \"USE_LORA\": \"1\",\n",
        "        \"TRAIN_LORA_ONLY\": \"1\",\n",
        "        \"LORA_MODE\": \"all\",\n",
        "        \"LORA_STEPS\": \"40\",\n",
        "        \"LOG_MLFLOW\": \"1\",\n",
        "    },\n",
        "\n",
        "    # --- Add-variable demo (example: 2m dewpoint) ---\n",
        "    \"era5_add_variable_demo\": {\n",
        "        \"FLOW\": \"era5\",\n",
        "        \"FT_MODE\": \"short\",\n",
        "        \"FINETUNE_STEPS\": \"3\",\n",
        "        \"ERA5_LEAD_HOURS\": \"6\",\n",
        "        \"ERA5_CROP_LAT\": str(CROP_LAT),\n",
        "        \"ERA5_CROP_LON\": str(CROP_LON),\n",
        "        \"ERA5_TIME_INDEX\": \"10\",\n",
        "        \"AUTOCAST\": \"1\",\n",
        "        \"LR\": str(LR),\n",
        "        \"USE_LORA\": \"1\",\n",
        "        \"TRAIN_LORA_ONLY\": \"1\",\n",
        "        \"LORA_MODE\": \"single\",\n",
        "        \"LORA_STEPS\": \"40\",\n",
        "\n",
        "        # Extra variable config (surface var example)\n",
        "        \"EXTRA_KIND\": \"surf\",\n",
        "        \"EXTRA_KEY\": \"d2m\",                       # Aurora key you choose\n",
        "        \"EXTRA_SRC\": \"2m_dewpoint_temperature\",   # must exist in the PLUS dataset\n",
        "        \"EXTRA_LOCATION\": \"0.0\",                  # set real stats if you can\n",
        "        \"EXTRA_SCALE\": \"1.0\",\n",
        "    },\n",
        "    \"era5_rollout_no_lora\": {\n",
        "    \"FLOW\": \"era5\",\n",
        "    \"FT_MODE\": \"rollout\",\n",
        "\n",
        "    \"FINETUNE_STEPS\": \"5\",         \n",
        "    \"ERA5_LEAD_HOURS\": \"6\",\n",
        "    \"ERA5_TIME_INDEX\": \"10\",\n",
        "    \"ERA5_CROP_LAT\": str(CROP_LAT),\n",
        "    \"ERA5_CROP_LON\": str(CROP_LON),\n",
        "    \"AUTOCAST\": \"1\",\n",
        "    \"LR\": str(LR),\n",
        "\n",
        "    \"ROLLOUT_HORIZON_STEPS\": \"8\",   \n",
        "    \"ROLLOUT_LOSS_ON\": \"last\",      \n",
        "\n",
        "    \"USE_LORA\": \"0\",\n",
        "    \"TRAIN_LORA_ONLY\": \"0\", \n",
        "    \"LOG_MLFLOW\": \"1\",    \n",
        "\n",
        "    \n",
        "    },\n",
        "\n",
        "}\n",
        "\n",
        "# Pick one:\n",
        "RUN_PROFILE = \"era5_rollout_no_lora\"   # toy | era5_short | era5_short_lora | era5_rollout_infer_48h | era5_rollout_ft_safe | era5_rollout_ft_2days | era5_add_variable_demo\n",
        "\n",
        "if RUN_PROFILE not in profiles:\n",
        "    raise ValueError(f\"Unknown RUN_PROFILE: {RUN_PROFILE}. Choose one of: {list(profiles)}\")\n",
        "\n",
        "env_vars = dict(profiles[RUN_PROFILE]) \n",
        "\n",
        "# Make sure we always set these\n",
        "env_vars[\"PARTICIPANT_ID\"] = PARTICIPANT_ID\n",
        "env_vars[\"DEVICE\"] = env_vars.get(\"DEVICE\", \"cuda\")\n",
        "\n",
        "# This helps reduce CUDA memory fragmentation in some training runs\n",
        "env_vars[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"backend:cudaMallocAsync\"\n",
        "\n",
        "# Pick which dynamic asset to mount\n",
        "if RUN_PROFILE == \"era5_add_variable_demo\":\n",
        "    SELECTED_ERA5_ZARR_ASSET = ERA5_ZARR_ASSET_PLUS\n",
        "else:\n",
        "    SELECTED_ERA5_ZARR_ASSET = ERA5_ZARR_ASSET\n",
        "\n",
        "print(\"RUN_PROFILE:\", RUN_PROFILE)\n",
        "print(\"Dynamic asset:\", SELECTED_ERA5_ZARR_ASSET)\n",
        "print(\"Static asset :\", ERA5_STATIC_ASSET)\n",
        "print(\"Env vars to job (preview):\")\n",
        "for k in sorted(env_vars.keys()):\n",
        "    print(f\"  {k}={env_vars[k]}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RUN_PROFILE: era5_rollout_no_lora\nDynamic asset: azureml:era5_aurora_2025-09_6hourly_zarr:2\nStatic asset : azureml:era5_static_nc:2\nEnv vars to job (preview):\n  AUTOCAST=1\n  DEVICE=cuda\n  ERA5_CROP_LAT=128\n  ERA5_CROP_LON=256\n  ERA5_LEAD_HOURS=6\n  ERA5_TIME_INDEX=10\n  FINETUNE_STEPS=5\n  FLOW=era5\n  FT_MODE=rollout\n  LOG_MLFLOW=1\n  LR=3e-05\n  PARTICIPANT_ID=saadat\n  PYTORCH_CUDA_ALLOC_CONF=backend:cudaMallocAsync\n  ROLLOUT_HORIZON_STEPS=8\n  ROLLOUT_LOSS_ON=last\n  TRAIN_LORA_ONLY=0\n  USE_LORA=0\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1768467602077
        }
      },
      "id": "3da0e098-8b76-4a49-8b73-579dee448a73"
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit the Azure ML job\n",
        "# This creates one job that runs on the GPU cluster.\n",
        "# The job executes:  python run_aurora_job.py\n",
        "\n",
        "# NOTE: For ERA5 flows, we mount two inputs:\n",
        "#   - era5_zarr   (URI_FOLDER)\n",
        "#   - era5_static (URI_FILE)\n",
        "# and pass their mounted paths to the script via env vars.\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "from azure.ai.ml import command, Input, Output\n",
        "\n",
        "\n",
        "\n",
        "# Make a unique job name every submission\n",
        "run_suffix = datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# Separate experiments so toy doesn't mix with ERA5\n",
        "flow = env_vars.get(\"FLOW\", \"toy\").lower()\n",
        "if flow == \"toy\":\n",
        "    EXPERIMENT_NAME = f\"aurora_workshop_{PARTICIPANT_ID}_toy\"\n",
        "else:\n",
        "    EXPERIMENT_NAME = f\"aurora_workshop_{PARTICIPANT_ID}_era5\"\n",
        "\n",
        "JOB_NAME = f\"aurora-{PARTICIPANT_ID}-{RUN_PROFILE}-{run_suffix}\"\n",
        "\n",
        "DISPLAY_NAME = f\"Aurora | {PARTICIPANT_ID} | {RUN_PROFILE} | {run_suffix}\"\n",
        "\n",
        "# Build inputs only when needed\n",
        "inputs = {}\n",
        "if env_vars[\"FLOW\"] == \"era5\":\n",
        "    inputs = {\n",
        "        \"era5_zarr\": Input(type=\"uri_folder\", path=SELECTED_ERA5_ZARR_ASSET, mode=\"ro_mount\"),\n",
        "        \"era5_static\": Input(type=\"uri_file\", path=ERA5_STATIC_ASSET, mode=\"ro_mount\"),\n",
        "    }\n",
        "\n",
        "\n",
        "# Output folder (Azure ML will mount this)\n",
        "outputs = {\"out_dir\": Output(type=\"uri_folder\", mode=\"rw_mount\")}\n",
        "\n",
        "env_vars[\"PARENT_JOB_NAME\"] = JOB_NAME\n",
        "\n",
        "job = command(\n",
        "    name=JOB_NAME,\n",
        "    display_name=DISPLAY_NAME,\n",
        "    experiment_name=EXPERIMENT_NAME,\n",
        "    code=\".\",\n",
        "    command=(\n",
        "    \"python -m pip uninstall -y mlflow mlflow-skinny mlflow-tracing || true && \"\n",
        "    \"python -m pip install -q --upgrade 'zarr<3' numcodecs fasteners asciitree && \"\n",
        "    \"python -m pip install -q --upgrade azureml-mlflow && \"\n",
        "\n",
        "    \"export OUT_DIR='${{outputs.out_dir}}' && \"\n",
        "    + (\n",
        "        \"export ERA5_ZARR_PATH='${{inputs.era5_zarr}}' && \"\n",
        "        \"export ERA5_STATIC_NC='${{inputs.era5_static}}' && \"\n",
        "        if flow == \"era5\" else \"\"\n",
        "    ) +\n",
        "    \"PYTHONPATH=$PWD python run_aurora_job.py\"\n",
        "),\n",
        "    environment=ENV_NAME,\n",
        "    compute=COMPUTE_NAME,\n",
        "    inputs=inputs,\n",
        "    outputs=outputs,\n",
        "    environment_variables=env_vars,\n",
        "     tags={\n",
        "        \"participant_id\": PARTICIPANT_ID,\n",
        "        \"run_profile\": RUN_PROFILE,\n",
        "        \"flow\": flow,\n",
        "    },\n",
        "    resources={\"instance_count\": 1},\n",
        ")\n",
        "\n",
        "print(\"Submitting job:\", JOB_NAME)\n",
        "returned_job = ml_client.jobs.create_or_update(job)\n",
        "print(\"Job name:\", returned_job.name)\n",
        "\n",
        "print(\"Streaming logs…\")\n",
        "ml_client.jobs.stream(returned_job.name)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitting job: aurora-saadat-era5_rollout_no_lora-20260115-090019\nJob name: aurora-saadat-era5_rollout_no_lora-20260115-090019\nStreaming logs…\nRunId: aurora-saadat-era5_rollout_no_lora-20260115-090019\nWeb View: https://ml.azure.com/runs/aurora-saadat-era5_rollout_no_lora-20260115-090019?wsid=/subscriptions/62118f5c-be37-400f-9f20-a8b77a2a7877/resourcegroups/aurora-workshop-rg/workspaces/aurora-workshop-aml-ws\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Your file exceeds 100 MB. If you experience low speeds, latency, or broken connections, we recommend using the AzCopyv10 tool for this file transfer.\n\nExample: azcopy copy '/mnt/batch/tasks/shared/LS_root/mounts/clusters/aurora-ws-cpu-cls/code/Users/saadatali/Updated' 'https://auroraworkshop7918090421.blob.core.windows.net/fe6df4e0-19e0-41f0-9fdb-8eddf05a138a-p8lfl15ycgwib8elz6zzrus74z/Updated' \n\nSee https://learn.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n\u001b[32mUploading Updated (5045.53 MBs): 100%|██████████| 5045530808/5045530808 [00:15<00:00, 319657244.05it/s]\n\u001b[39m\n\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1768467394961
        }
      },
      "id": "bd8c4e1c-e4d5-4669-abf3-b852262cf595"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## After the job finishes\n",
        "\n",
        "The next cell downloads the job outputs to a local folder, then shows quick plots.\n",
        "\n",
        "Files you’ll typically see:\n",
        "- `inference_2t.npy`\n",
        "- `finetune_last_2t.npy` (if FINETUNE_STEPS > 0)\n",
        "- `inference_rollout_2t.npy` (if INFER_ROLLOUT_STEPS was set)\n",
        "- `finetune_losses.npy` / `finetune_losses.json`\n",
        "- `finetuned_state_dict.pt` (full model, or LoRA-only weights if TRAIN_LORA_ONLY=1)\n",
        "\n",
        "If you’re doing rollout inference, the rollout file is a stack:\n",
        "`(steps, batch, time, H, W)`.\n"
      ],
      "metadata": {},
      "id": "34e6d36d-5a93-4ab9-90c7-f1f05372de62"
    },
    {
      "cell_type": "code",
      "source": [
        "# Download outputs + quick plots\n",
        "# ------------------------------\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "download_root = Path(\"job_outputs\") / returned_job.name\n",
        "download_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Downloading outputs to:\", download_root)\n",
        "\n",
        "# Azure ML SDK has slightly different download() signatures across versions, so we try a couple.\n",
        "downloaded = False\n",
        "last_err = None\n",
        "for kwargs in [\n",
        "    {\"name\": returned_job.name, \"download_path\": str(download_root)},\n",
        "    {\"job_name\": returned_job.name, \"download_path\": str(download_root)},\n",
        "    {\"name\": returned_job.name, \"download_path\": str(download_root), \"all\": True},\n",
        "]:\n",
        "    try:\n",
        "        ml_client.jobs.download(**kwargs)\n",
        "        downloaded = True\n",
        "        break\n",
        "    except TypeError:\n",
        "        continue\n",
        "    except Exception as e:\n",
        "        last_err = e\n",
        "\n",
        "if not downloaded:\n",
        "    raise RuntimeError(f\"Could not download job outputs. Last error: {repr(last_err)}\")\n",
        "\n",
        "# The job writes outputs under out_dir/<PARTICIPANT_ID>/...\n",
        "# We'll try to find that folder. If we can't, we just use the download root.\n",
        "participant_dir = None\n",
        "for p in download_root.rglob(PARTICIPANT_ID):\n",
        "    if p.is_dir():\n",
        "        participant_dir = p\n",
        "        break\n",
        "\n",
        "if participant_dir is None:\n",
        "    participant_dir = download_root\n",
        "\n",
        "print(\"Using output folder:\", participant_dir)\n",
        "\n",
        "def load_npy(name: str):\n",
        "    p = participant_dir / name\n",
        "    if p.exists():\n",
        "        return np.load(p)\n",
        "    return None\n",
        "\n",
        "inf_2t = load_npy(\"inference_2t.npy\")\n",
        "fin_2t = load_npy(\"finetune_last_2t.npy\")\n",
        "roll_2t = load_npy(\"inference_rollout_2t.npy\")\n",
        "losses = load_npy(\"finetune_losses.npy\")\n",
        "\n",
        "print(\"Found files:\")\n",
        "for fname in [\n",
        "    \"inference_2t.npy\",\n",
        "    \"finetune_last_2t.npy\",\n",
        "    \"inference_rollout_2t.npy\",\n",
        "    \"finetune_losses.npy\",\n",
        "    \"finetuned_state_dict.pt\",\n",
        "]:\n",
        "    print(\" -\", fname, \"✅\" if (participant_dir / fname).exists() else \"—\")\n",
        "\n",
        "def show_field(ax, arr, title):\n",
        "    im = ax.imshow(arr, origin=\"lower\", aspect=\"auto\")\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "\n",
        "# Extract 2D fields for plotting\n",
        "inf_field = inf_2t[0, 0] if inf_2t is not None else None\n",
        "fin_field = fin_2t[0, 0] if fin_2t is not None else None\n",
        "\n",
        "# For rollout inference, take the last step for display (shape: steps,1,1,H,W)\n",
        "roll_last_field = roll_2t[-1, 0, 0] if roll_2t is not None else None\n",
        "\n",
        "plots = []\n",
        "if inf_field is not None:\n",
        "    plots.append((\"Inference (single-step)\", inf_field))\n",
        "if roll_last_field is not None:\n",
        "    plots.append((\"Inference (rollout last step)\", roll_last_field))\n",
        "if fin_field is not None:\n",
        "    plots.append((\"After fine-tuning\", fin_field))\n",
        "if (inf_field is not None) and (fin_field is not None):\n",
        "    plots.append((\"Difference (finetune - inference)\", fin_field - inf_field))\n",
        "\n",
        "if plots:\n",
        "    fig, axes = plt.subplots(1, len(plots), figsize=(5 * len(plots), 4), constrained_layout=True)\n",
        "    if len(plots) == 1:\n",
        "        axes = [axes]\n",
        "    for ax, (title, arr) in zip(axes, plots):\n",
        "        show_field(ax, arr, title)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No 2t output files were found to plot.\")\n",
        "\n",
        "# Plot loss curve if we have it\n",
        "if losses is not None and len(losses) > 0:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(losses)\n",
        "    plt.title(\"Fine-tuning loss (per step)\")\n",
        "    plt.xlabel(\"Step\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Downloading outputs to: job_outputs/aurora-saadat-era5_short-20260111-214538\nUsing output folder: job_outputs/aurora-saadat-era5_short-20260111-214538\nFound files:\n - inference_2t.npy —\n - finetune_last_2t.npy —\n - inference_rollout_2t.npy —\n - finetune_losses.npy —\n - finetuned_state_dict.pt —\nNo 2t output files were found to plot.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Downloading artifact azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.aurora-saadat-era5_short-20260111-214538 to job_outputs/aurora-saadat-era5_short-20260111-214538/artifacts\n"
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1768169143159
        }
      },
      "id": "17f032e2-0408-4294-aa61-6579820640c3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}